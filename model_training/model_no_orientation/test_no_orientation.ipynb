{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modules.modules import HyperNet, MainNet\n",
    "import ikpy.chain\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chain_path': 'assets/UR5/urdf/ur5_robot.urdf',\n",
       " 'train_data_path': 'data/ur5/ur5_train_data_87k.csv',\n",
       " 'test_data_path': 'data/ur5/ur5_test_data_87k.csv',\n",
       " 'num_joints': 6,\n",
       " 'lr': 0.001,\n",
       " 'num_epochs': 200,\n",
       " 'num_solutions_validation': 10,\n",
       " 'batch_size': 1024,\n",
       " 'early_stopping_epochs': 30,\n",
       " 'grad_clip': 1,\n",
       " 'embedding_dim': 128,\n",
       " 'hypernet_input_dim': 3,\n",
       " 'hypernet_hidden_size': 1024,\n",
       " 'hypernet_num_hidden_layers': 3,\n",
       " 'jointnet_hidden_size': 256,\n",
       " 'num_gaussians': 50,\n",
       " 'exp_dir': 'runs'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"chain_path\": \"assets/UR5/urdf/ur5_robot.urdf\",\n",
    "  \"train_data_path\": \"data/ur5/ur5_train_data_87k.csv\",\n",
    "  \"test_data_path\": \"data/ur5/ur5_test_data_87k.csv\",\n",
    "  \"num_joints\": 6,\n",
    "  \"lr\": 0.001,\n",
    "  \"num_epochs\": 200,\n",
    "  \"num_solutions_validation\": 10,\n",
    "  \"batch_size\": 1024,\n",
    "  \"early_stopping_epochs\": 30,\n",
    "  \"grad_clip\": 1,\n",
    "  \"embedding_dim\": 128,\n",
    "  \"hypernet_input_dim\": 3,\n",
    "  \"hypernet_hidden_size\": 1024,\n",
    "  \"hypernet_num_hidden_layers\": 3,\n",
    "  \"jointnet_hidden_size\": 256,\n",
    "  \"num_gaussians\": 50,\n",
    "  \"exp_dir\": \"runs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime Configuration\n",
    "class Config:\n",
    "    chain_path=\"assets/UR5/urdf/ur5_robot.urdf\"\n",
    "    train_data_path=\"data/ur5/ur5_train_data_87k.csv\"\n",
    "    test_data_path=\"data/ur5/ur5_test_data_87k.csv\"\n",
    "    num_joints=6\n",
    "    lr=0.001\n",
    "    num_epochs=200\n",
    "    num_solutions_validation=10\n",
    "    batch_size=1024\n",
    "    early_stopping_epochs=30\n",
    "    grad_clip=1\n",
    "    embedding_dim=128\n",
    "    hypernet_input_dim=3\n",
    "    hypernet_hidden_size=1024\n",
    "    hypernet_num_hidden_layers=3\n",
    "    jointnet_hidden_size=256\n",
    "    num_gaussians=50\n",
    "    #exp_dir='runs/exp_1'\n",
    "    jointnet_output_dim=150\n",
    "    jointnet_output_dim = 2 if num_gaussians == 1 else num_gaussians * 2 + num_gaussians\n",
    "\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HyperNet and MainNet\n",
    "hypernet = HyperNet(cfg)\n",
    "mainnet = MainNet(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAE\\AppData\\Local\\Temp\\ipykernel_12184\\2993810607.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hypernet.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyperNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=3, out_features=1024, bias=True)\n",
       "    (1-2): 2 x Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (projection): MultiHeadLinearProjection(\n",
       "    (linears): ModuleList(\n",
       "      (0-1): 2 x ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (10): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (12): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (13): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (14): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (15): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (16): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (17): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (19): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (20): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=1536, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (21): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (22): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (23): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1-3): 3 x BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model weights into HyperNet\n",
    "model_path = \"runs/exp_1/best_model.pt\"\n",
    "hypernet.load_state_dict(torch.load(model_path))\n",
    "hypernet.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move models to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hypernet = hypernet.to(device)\n",
    "mainnet = mainnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAE\\Desktop\\Organisatorisches\\FH\\AI\\3. Semester\\ROBOTICS\\robotics_project\\.venv\\Lib\\site-packages\\ikpy\\chain.py:60: UserWarning: Link Base link (index: 0) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\n",
      "  warnings.warn(\"Link {} (index: {}) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\".format(link.name, link_index))\n",
      "c:\\Users\\SAE\\Desktop\\Organisatorisches\\FH\\AI\\3. Semester\\ROBOTICS\\robotics_project\\.venv\\Lib\\site-packages\\ikpy\\chain.py:60: UserWarning: Link ee_fixed_joint (index: 7) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\n",
      "  warnings.warn(\"Link {} (index: {}) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\".format(link.name, link_index))\n"
     ]
    }
   ],
   "source": [
    "# Load the kinematic chain for FK calculations (optional)\n",
    "r_arm = ikpy.chain.Chain.from_urdf_file(cfg.chain_path)\n",
    "\n",
    "# Extract joint limits\n",
    "upper = []\n",
    "lower = []\n",
    "for i in range(1, len(r_arm.links) - 1):\n",
    "    lower.append(r_arm.links[i].bounds[0])\n",
    "    upper.append(r_arm.links[i].bounds[1])\n",
    "\n",
    "upper = np.array(upper)\n",
    "lower = np.array(lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input position (e.g., desired end-effector position)\n",
    "positions = torch.tensor([[0.5, 0.2, 0.3]], dtype=torch.float32)  # Replace with your input positions\n",
    "positions = positions.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict weights using HyperNet\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    predicted_weights = hypernet(positions)\n",
    "\n",
    "# Generate joint angles using MainNet\n",
    "with torch.no_grad():\n",
    "    initial_input = torch.ones((positions.shape[0], 1), dtype=torch.float32).to(device)\n",
    "    samples, distributions, means, variance, selection = mainnet.validate(\n",
    "        initial_input, predicted_weights, lower, upper\n",
    "    )\n",
    "\n",
    "# Convert the predicted joint angles to a readable format\n",
    "predicted_joint_angles = []\n",
    "for sample in samples:\n",
    "    predicted_joint_angles.append([angle.item() for angle in sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.19980783760547638],\n",
       " [0.31278616189956665],\n",
       " [-1.3417049646377563],\n",
       " [2.6824393272399902],\n",
       " [-1.1563910245895386],\n",
       " [0.06763893365859985]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_joint_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the predicted joint angles\n",
    "flat_joint_angles = [angle[0] for angle in predicted_joint_angles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add base and end-effector placeholders (if necessary)\n",
    "full_joint_angles = [0] + flat_joint_angles + [0]  # Base and end-effector placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.19980783760547638,\n",
       " 0.31278616189956665,\n",
       " -1.3417049646377563,\n",
       " 2.6824393272399902,\n",
       " -1.1563910245895386,\n",
       " 0.06763893365859985,\n",
       " 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_joint_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r_arm.links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check for length mismatch\n",
    "if len(full_joint_angles) != len(r_arm.links):\n",
    "    raise ValueError(\"Mismatch between joint angles and kinematic chain.\")\n",
    "\n",
    "# Compute Forward Kinematics\n",
    "fk_position = r_arm.forward_kinematics(full_joint_angles)[:3, 3]  # Extract end-effector position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FK Position using predicted joints: [0.48001995 0.24238489 0.377336  ]\n",
      "original position: tensor([0.5000, 0.2000, 0.3000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"FK Position using predicted joints: {fk_position}\")\n",
    "print(f\"original position: {positions[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_parameters(model):\n",
    "\n",
    "    if isinstance(model, dict) and 'model_state_dict' in model:  # Checkpoint format\n",
    "        raise ValueError(\"The file appears to be a state_dict checkpoint. Please load the corresponding model class first.\")\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": total_params,\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"non_trainable_params\": total_params - trainable_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = count_model_parameters(hypernet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_params': 32969994,\n",
       " 'trainable_params': 32969994,\n",
       " 'non_trainable_params': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_3\n",
    "# {'total_params': 172044274,\n",
    "#  'trainable_params': 172044274,\n",
    "#  'non_trainable_params': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_csv import IKDatasetValCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = IKDatasetValCSV(\"ur5_val_data_87k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(hypernet, mainnet, dataloader, r_arm, lower, upper, threshold=0.1):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    hypernet.eval()\n",
    "    mainnet.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for positions, joint_angles in dataloader:\n",
    "            # Ensure input is 2D: [batch_size, num_features]\n",
    "            positions = positions.to(device).view(-1, positions.shape[-1])\n",
    "\n",
    "            # Predict mixture weights with hypernet\n",
    "            predicted_weights = hypernet(positions)\n",
    "\n",
    "            # Generate joint angle predictions using mainnet\n",
    "            initial_input = torch.ones((positions.shape[0], 1), dtype=torch.float32).to(device)\n",
    "            samples, _, _, _, _ = mainnet.validate(initial_input, predicted_weights, lower, upper)\n",
    "\n",
    "            for i in range(len(positions)):\n",
    "                # Construct joint angles for forward kinematics\n",
    "                flat_joint_angles = [sample[i].item() for sample in samples]\n",
    "                full_joint_angles = [0] + flat_joint_angles + [0]  # Add base and end-effector placeholders\n",
    "\n",
    "                # Compute FK\n",
    "                fk_position = r_arm.forward_kinematics(full_joint_angles)[:3, 3]\n",
    "\n",
    "                # Compare with target end-effector position\n",
    "                target_position = positions[i, :3].cpu().numpy()\n",
    "                error = np.linalg.norm(fk_position - target_position)\n",
    "\n",
    "                # Count as correct if within threshold\n",
    "                if error < threshold:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}% (threshold: {threshold} meters)\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.76% (threshold: 0.1 meters)\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(hypernet, mainnet, dataloader, r_arm, lower, upper, threshold=0.1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

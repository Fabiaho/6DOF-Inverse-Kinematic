{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modules.modules import HyperNet, MainNet\n",
    "import ikpy.chain\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime Configuration\n",
    "class Config:\n",
    "    chain_path='assets/UR5/urdf/ur5_robot.urdf'\n",
    "    train_data_path='data/ur5/ur5_train_data.csv'\n",
    "    test_data_path='data/ur5/ur5_test_data.csv'\n",
    "    num_joints=6\n",
    "    lr=0.001\n",
    "    num_epochs=200\n",
    "    num_solutions_validation=10\n",
    "    batch_size=1024\n",
    "    early_stopping_epochs=30\n",
    "    grad_clip=1\n",
    "    embedding_dim=128\n",
    "    hypernet_input_dim=6\n",
    "    hypernet_hidden_size=1024\n",
    "    hypernet_num_hidden_layers=3\n",
    "    jointnet_hidden_size=256\n",
    "    num_gaussians=50\n",
    "    exp_dir='runs/exp_12'\n",
    "    jointnet_output_dim=150\n",
    "    jointnet_output_dim = 2 if num_gaussians == 1 else num_gaussians * 2 + num_gaussians\n",
    "\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HyperNet and MainNet\n",
    "hypernet = HyperNet(cfg)\n",
    "mainnet = MainNet(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAE\\AppData\\Local\\Temp\\ipykernel_26448\\629899569.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hypernet.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyperNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=6, out_features=1024, bias=True)\n",
       "    (1-2): 2 x Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (projection): MultiHeadLinearProjection(\n",
       "    (linears): ModuleList(\n",
       "      (0-1): 2 x ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (10): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (12): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (13): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (14): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (15): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (16): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (17): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (19): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (20): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=1536, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (21): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (22): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=38400, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (23): ProjectionHead(\n",
       "        (head): Sequential(\n",
       "          (linear_final): Linear(in_features=128, out_features=150, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model weights into HyperNet\n",
    "model_path = \"runs/exp_11/best_model.pt\"\n",
    "hypernet.load_state_dict(torch.load(model_path))\n",
    "hypernet.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move models to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hypernet = hypernet.to(device)\n",
    "mainnet = mainnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAE\\Desktop\\Organisatorisches\\FH\\AI\\3. Semester\\robotics_project\\.venv\\Lib\\site-packages\\ikpy\\chain.py:60: UserWarning: Link Base link (index: 0) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\n",
      "  warnings.warn(\"Link {} (index: {}) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\".format(link.name, link_index))\n",
      "c:\\Users\\SAE\\Desktop\\Organisatorisches\\FH\\AI\\3. Semester\\robotics_project\\.venv\\Lib\\site-packages\\ikpy\\chain.py:60: UserWarning: Link ee_fixed_joint (index: 7) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\n",
      "  warnings.warn(\"Link {} (index: {}) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\".format(link.name, link_index))\n"
     ]
    }
   ],
   "source": [
    "# Load the kinematic chain for FK calculations (optional)\n",
    "r_arm = ikpy.chain.Chain.from_urdf_file(cfg.chain_path)\n",
    "\n",
    "# Extract joint limits\n",
    "upper = []\n",
    "lower = []\n",
    "for i in range(1, len(r_arm.links) - 1):\n",
    "    lower.append(r_arm.links[i].bounds[0])\n",
    "    upper.append(r_arm.links[i].bounds[1])\n",
    "\n",
    "upper = np.array(upper)\n",
    "lower = np.array(lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input position (e.g., desired end-effector position)\n",
    "positions = torch.tensor([[0.5, 0.2, 0.3, 0, 0, 0]], dtype=torch.float32)  # Replace with your input positions\n",
    "positions = positions.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict weights using HyperNet\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    predicted_weights = hypernet(positions)\n",
    "\n",
    "# Generate joint angles using MainNet\n",
    "with torch.no_grad():\n",
    "    initial_input = torch.ones((positions.shape[0], 1), dtype=torch.float32).to(device)\n",
    "    samples, distributions, means, variance, selection = mainnet.validate(\n",
    "        initial_input, predicted_weights, lower, upper\n",
    "    )\n",
    "\n",
    "# Convert the predicted joint angles to a readable format\n",
    "predicted_joint_angles = []\n",
    "for sample in samples:\n",
    "    predicted_joint_angles.append([angle.item() for angle in sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2704930603504181],\n",
       " [-0.3294661045074463],\n",
       " [-0.9687324166297913],\n",
       " [1.6628884077072144],\n",
       " [-0.45977580547332764],\n",
       " [0.6450687050819397]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_joint_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the predicted joint angles\n",
    "flat_joint_angles = [angle[0] for angle in predicted_joint_angles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add base and end-effector placeholders (if necessary)\n",
    "full_joint_angles = [0] + flat_joint_angles + [0]  # Base and end-effector placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.2704930603504181,\n",
       " -0.3294661045074463,\n",
       " -0.9687324166297913,\n",
       " 1.6628884077072144,\n",
       " -0.45977580547332764,\n",
       " 0.6450687050819397,\n",
       " 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_joint_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r_arm.links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check for length mismatch\n",
    "if len(full_joint_angles) != len(r_arm.links):\n",
    "    raise ValueError(\"Mismatch between joint angles and kinematic chain.\")\n",
    "\n",
    "# Compute Forward Kinematics\n",
    "fk_position = r_arm.forward_kinematics(full_joint_angles)[:3, 3]  # Extract end-effector position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FK Position using predicted joints: [0.3750051  0.29378955 0.52902873]\n",
      "original position: tensor([0.5000, 0.2000, 0.3000, 0.0000, 0.0000, 0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"FK Position using predicted joints: {fk_position}\")\n",
    "print(f\"original position: {positions[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
